 1.Cluster:

 *Group of independent servers which are interconnected through a dedicated network to work as a single centralized
 data processing resource.

 * They are capable of performing multiple complex instructions by distributing workload across all connected servers.

 * Clustering is used to improve the system's availability to users, its aggregate performance, and tolerance to faults and 
  component failures.

* The  users are switched instantly to the other server when a server fails and the failed is automatically shut down.

Hadoop cluster:

 *A computer cluster used for Hadoop is called Hadoop Cluster which is used to boost the  speed of data analysis 
 applications

*Hadoop cluster is designed  for storing and analyzing large amounts of unstructured data.

*There are 3 types of nodes in Hadoop cluster

-master nodes
-worker nodes
-client nodes. 

*Clusters of three or more machines typically use a single NameNode and ResourceManager
 with all the other nodes as slave nodes. 

Advantages:

*Scalable
*Highly resistant to failures.
*Handles large amount of data
*It runs in low cost commodity hardwares.

2. Explain the components of Hadoop 1.x

 -The components of hadoop are:
   (1)HDFS
   (2)Map Reduce

HDFS

 *HDFS stands for Hadoop Distributed File System.
 *HDFS is developed using java.
 *It  deals with a storage of large amounts of data in a reliable manner and also it helps to stream the data to user 
 applications with high bandwidth.
 *Hadoop uses HDFS for storage purpose.
 *Hadoop Distributed File System take the data breaks them into pieces and distributes them to different nodes
  in a cluster and thus allows parallel processing.
 *HDFS is composed of two components.They are:
              -Namenode
              -Datanode
 *Namenode:
              - The namenode is used to store metadata.
              -It acts as the master node.
              -It stores the information about the data nodes like
               how many blocks are stored in the nodes,which node 
               holds the data,node locations etc.
 *Secondary namenode:
              -secondary namenodes performs house-keeping activities 
               for name node like periodic merging and it is used for edits. 

 *Datanode:
              -The data nodes are used to store the actual data.
              -It acts as slave nodes.
              -The default size of the block is 64MB.
              -It stores the data in terms of blocks
              -The data node acts as the heart beat of the name node 
               as it periodically sends signals to the name node
               to check whether it is active.

 Map Reduce

  *Map reduce is also known as distributed data processing or batch processing model 
   *It distributes the data across several machines.        

 - Map reduce is composed of two components .They are:
                -Job tracker.
                -Task tracker. 
*Job Tracker:
               -The main role of job tracker is to assign the map reduce task to the task tracker.
               -It is also used to re-assign some task to the other task tracker
                when the previous task trackers fails or when it gets shut down.
               -It is used to control the overall execution of map reduce.
               -Job tracker also maintains the status of the task tracker.

*Task Tracker:
               -The task tracker sends the status back to the job tracker              
               -The role of the task tracker is to execute the task assigned to it by the job tracker.
               -It periodically communicates with the task tracker.
               -It runs individual map-reduce tasks on the data nodes.


